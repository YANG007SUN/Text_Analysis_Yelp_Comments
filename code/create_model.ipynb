{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "XY9TOKfodvwH",
    "outputId": "43487367-500a-403e-9b37-ae1b550b90d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.0 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,435 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,404 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [146 kB]\n",
      "Fetched 3,271 kB in 3s (964 kB/s)\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Find the latest version of spark 2.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "spark_version = 'spark-2.4.7'\n",
    "# spark_version = 'spark-2.<enter version>'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5PNfsCGdvwK"
   },
   "outputs": [],
   "source": [
    "# Start Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"YelpReview\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRXeIzKxAbNl"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf,length, size\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Eo6aW_mIU7v"
   },
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "NaEsSu5HdvwN",
    "outputId": "e08d490c-3caa-41b3-976e-c5f5af71c5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+\n",
      "|             reviews|       rating|review_count|\n",
      "+--------------------+-------------+------------+\n",
      "|Panda Express was...|5 star rating|          63|\n",
      "|The dude and I ca...|5 star rating|          63|\n",
      "|I ordered 5 total...|1 star rating|          63|\n",
      "|I always order Pa...|3 star rating|          63|\n",
      "|Decided to try Pa...|5 star rating|          63|\n",
      "|I've never had a ...|4 star rating|          63|\n",
      "|The family meal d...|1 star rating|          63|\n",
      "|Quality has sever...|2 star rating|          63|\n",
      "|Paid for a bowl a...|1 star rating|          63|\n",
      "|Order a bowl with...|1 star rating|          63|\n",
      "|Went through the ...|1 star rating|          63|\n",
      "|When I think of p...|2 star rating|          63|\n",
      "|Horrible is a und...|1 star rating|          63|\n",
      "|Yes the drive thr...|2 star rating|          63|\n",
      "|Okay..so Panda is...|4 star rating|          63|\n",
      "|Going through Dri...|2 star rating|          63|\n",
      "|My entrees were a...|2 star rating|          63|\n",
      "|I'm done being ri...|1 star rating|          63|\n",
      "|Worst Panda in Fr...|1 star rating|          63|\n",
      "|I've been in here...|5 star rating|          63|\n",
      "+--------------------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in data from S3 Buckets\n",
    "from pyspark import SparkFiles\n",
    "url =\"https://usc-bootcamp-yelpreview-text-analysis.s3.us-east-2.amazonaws.com/reviews.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "raw_df = spark.read.csv(SparkFiles.get(\"reviews.csv\"), sep=\",\", header=True)\n",
    "\n",
    "# Show DataFrame\n",
    "raw_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BZ0W3-m8moG"
   },
   "outputs": [],
   "source": [
    "# new column function - reduce dimension of rating column into 3 categories\n",
    "def rating_category(rating:str)->str:\n",
    "  \"\"\"create new column for label\n",
    "  \"\"\"\n",
    "  if rating in [\"1 star rating\"]:\n",
    "      return \"bad\"\n",
    "  elif rating in [\"2 star rating\", \"3 star rating\"]:\n",
    "      return \"descent\"\n",
    "  else: \n",
    "      return \"good\"\n",
    "\n",
    "assert rating_category(\"1 star rating\")==\"bad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fXkOnFY-BPTG",
    "outputId": "7e21818a-6e55-4cfd-e72a-4ac10ad6144c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.rating_category>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store a user defined function\n",
    "convert_rating = udf(rating_category, StringType())\n",
    "convert_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "8-u1o_de3y1a",
    "outputId": "a82bff65-c401-4a4f-a6eb-cc4acd72f51c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+------------+------+\n",
      "|             reviews|       rating|review_count|output_label|length|\n",
      "+--------------------+-------------+------------+------------+------+\n",
      "|Panda Express was...|5 star rating|          63|        good|   334|\n",
      "|The dude and I ca...|5 star rating|          63|        good|   770|\n",
      "|I ordered 5 total...|1 star rating|          63|         bad|   151|\n",
      "|I always order Pa...|3 star rating|          63|     descent|   628|\n",
      "|Decided to try Pa...|5 star rating|          63|        good|   261|\n",
      "|I've never had a ...|4 star rating|          63|        good|   640|\n",
      "|The family meal d...|1 star rating|          63|         bad|   129|\n",
      "|Quality has sever...|2 star rating|          63|     descent|   350|\n",
      "|Paid for a bowl a...|1 star rating|          63|         bad|   158|\n",
      "|Order a bowl with...|1 star rating|          63|         bad|   151|\n",
      "|Went through the ...|1 star rating|          63|         bad|   675|\n",
      "|When I think of p...|2 star rating|          63|     descent|   269|\n",
      "|Horrible is a und...|1 star rating|          63|         bad|   480|\n",
      "|Yes the drive thr...|2 star rating|          63|     descent|   311|\n",
      "|Okay..so Panda is...|4 star rating|          63|        good|  1525|\n",
      "|Going through Dri...|2 star rating|          63|     descent|   653|\n",
      "|My entrees were a...|2 star rating|          63|     descent|   171|\n",
      "|I'm done being ri...|1 star rating|          63|         bad|  1065|\n",
      "|Worst Panda in Fr...|1 star rating|          63|         bad|   417|\n",
      "|I've been in here...|5 star rating|          63|        good|   410|\n",
      "+--------------------+-------------+------------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add new column\n",
    "selected_df = raw_df.withColumn(\"output_label\", convert_rating(col(\"rating\")))\n",
    "selected_df = selected_df.withColumn(\"length\", length(selected_df[\"reviews\"]))\n",
    "selected_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Gw825XQD9ZR"
   },
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-YLw4x6D3Xi"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "DZ3s8Aq7vg_p",
    "outputId": "559bf79f-c791-4fe5-867e-b6d50ab44437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+\n",
      "|             reviews|       rating|review_count|output_label|length|               token|      filtered_token|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+\n",
      "|Panda Express was...|5 star rating|          63|        good|   334|[panda, express, ...|[panda, express, ...|\n",
      "|The dude and I ca...|5 star rating|          63|        good|   770|[the, dude, and, ...|[dude, came, pand...|\n",
      "|I ordered 5 total...|1 star rating|          63|         bad|   151|[i, ordered, 5, t...|[ordered, 5, tota...|\n",
      "|I always order Pa...|3 star rating|          63|     descent|   628|[i, always, order...|[always, order, p...|\n",
      "|Decided to try Pa...|5 star rating|          63|        good|   261|[decided, to, try...|[decided, try, pa...|\n",
      "|I've never had a ...|4 star rating|          63|        good|   640|[i've, never, had...|[never, bad, expe...|\n",
      "|The family meal d...|1 star rating|          63|         bad|   129|[the, family, mea...|[family, meal, de...|\n",
      "|Quality has sever...|2 star rating|          63|     descent|   350|[quality, has, se...|[quality, severel...|\n",
      "|Paid for a bowl a...|1 star rating|          63|         bad|   158|[paid, for, a, bo...|[paid, bowl, entr...|\n",
      "|Order a bowl with...|1 star rating|          63|         bad|   151|[order, a, bowl, ...|[order, bowl, cho...|\n",
      "|Went through the ...|1 star rating|          63|         bad|   675|[went, through, t...|[went, drive-thro...|\n",
      "|When I think of p...|2 star rating|          63|     descent|   269|[when, i, think, ...|[think, panda, go...|\n",
      "|Horrible is a und...|1 star rating|          63|         bad|   480|[horrible, is, a,...|[horrible, unders...|\n",
      "|Yes the drive thr...|2 star rating|          63|     descent|   311|[yes, the, drive,...|[yes, drive, fast...|\n",
      "|Okay..so Panda is...|4 star rating|          63|        good|  1525|[okay..so, panda,...|[okay..so, panda,...|\n",
      "|Going through Dri...|2 star rating|          63|     descent|   653|[going, through, ...|[going, drive-thr...|\n",
      "|My entrees were a...|2 star rating|          63|     descent|   171|[my, entrees, wer...|[entrees, poor, s...|\n",
      "|I'm done being ri...|1 star rating|          63|         bad|  1065|[i'm, done, being...|[done, ripped, lo...|\n",
      "|Worst Panda in Fr...|1 star rating|          63|         bad|   417|[worst, panda, in...|[worst, panda, fr...|\n",
      "|I've been in here...|5 star rating|          63|        good|   410|[i've, been, in, ...|[many, times, say...|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create token and remove stop words in order to find out stopwords percentage\n",
    "tokenizer = Tokenizer(inputCol=\"reviews\", outputCol=\"token\")\n",
    "selected_df = tokenizer.transform(selected_df)\n",
    "stop_word_remover = StopWordsRemover(inputCol=\"token\", outputCol=\"filtered_token\")\n",
    "selected_df = stop_word_remover.transform(selected_df)\n",
    "selected_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "xyh8KYgKwp-n",
    "outputId": "a8011009-00d5-4aae-b92e-641799023b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+\n",
      "|             reviews|       rating|review_count|output_label|length|               token|      filtered_token|stopwords_count|  stopwords_percent|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+\n",
      "|Panda Express was...|5 star rating|          63|        good|   334|[panda, express, ...|[panda, express, ...|             37|0.11077844311377245|\n",
      "|The dude and I ca...|5 star rating|          63|        good|   770|[the, dude, and, ...|[dude, came, pand...|             80| 0.1038961038961039|\n",
      "|I ordered 5 total...|1 star rating|          63|         bad|   151|[i, ordered, 5, t...|[ordered, 5, tota...|             22| 0.1456953642384106|\n",
      "|I always order Pa...|3 star rating|          63|     descent|   628|[i, always, order...|[always, order, p...|             60|0.09554140127388536|\n",
      "|Decided to try Pa...|5 star rating|          63|        good|   261|[decided, to, try...|[decided, try, pa...|             32|0.12260536398467432|\n",
      "|I've never had a ...|4 star rating|          63|        good|   640|[i've, never, had...|[never, bad, expe...|             60|            0.09375|\n",
      "|The family meal d...|1 star rating|          63|         bad|   129|[the, family, mea...|[family, meal, de...|             13|0.10077519379844961|\n",
      "|Quality has sever...|2 star rating|          63|     descent|   350|[quality, has, se...|[quality, severel...|             48|0.13714285714285715|\n",
      "|Paid for a bowl a...|1 star rating|          63|         bad|   158|[paid, for, a, bo...|[paid, bowl, entr...|             18|0.11392405063291139|\n",
      "|Order a bowl with...|1 star rating|          63|         bad|   151|[order, a, bowl, ...|[order, bowl, cho...|             19|0.12582781456953643|\n",
      "|Went through the ...|1 star rating|          63|         bad|   675|[went, through, t...|[went, drive-thro...|             62|0.09185185185185185|\n",
      "|When I think of p...|2 star rating|          63|     descent|   269|[when, i, think, ...|[think, panda, go...|             28|0.10408921933085502|\n",
      "|Horrible is a und...|1 star rating|          63|         bad|   480|[horrible, is, a,...|[horrible, unders...|             45|            0.09375|\n",
      "|Yes the drive thr...|2 star rating|          63|     descent|   311|[yes, the, drive,...|[yes, drive, fast...|             32|0.10289389067524116|\n",
      "|Okay..so Panda is...|4 star rating|          63|        good|  1525|[okay..so, panda,...|[okay..so, panda,...|            149|0.09770491803278689|\n",
      "|Going through Dri...|2 star rating|          63|     descent|   653|[going, through, ...|[going, drive-thr...|             64|0.09800918836140889|\n",
      "|My entrees were a...|2 star rating|          63|     descent|   171|[my, entrees, wer...|[entrees, poor, s...|             21|0.12280701754385964|\n",
      "|I'm done being ri...|1 star rating|          63|         bad|  1065|[i'm, done, being...|[done, ripped, lo...|            106|0.09953051643192488|\n",
      "|Worst Panda in Fr...|1 star rating|          63|         bad|   417|[worst, panda, in...|[worst, panda, fr...|             47|0.11270983213429256|\n",
      "|I've been in here...|5 star rating|          63|        good|   410|[i've, been, in, ...|[many, times, say...|             37|0.09024390243902439|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_df = selected_df.withColumn(\"stopwords_count\", size(selected_df[\"filtered_token\"]))\n",
    "selected_df = selected_df.withColumn(\"stopwords_percent\", selected_df[\"stopwords_count\"]/selected_df[\"length\"])\n",
    "selected_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qz57Y3xxEHRJ"
   },
   "outputs": [],
   "source": [
    "# create all features to the dataset\n",
    "label_encoder = StringIndexer(inputCol=\"output_label\", outputCol=\"label\")\n",
    "hasher = HashingTF(inputCol=\"filtered_token\", outputCol=\"hashed_token\")\n",
    "idf = IDF(inputCol=\"hashed_token\", outputCol=\"idf_token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmeYECzrEHTd"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors\n",
    "vectorizer = VectorAssembler(inputCols = [\"idf_token\", \"length\",\"stopwords_percent\"], outputCol = \"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4U-I2I6FTV9"
   },
   "source": [
    "### Create a Pipeline to Automate The Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6EGuPcMFVop"
   },
   "outputs": [],
   "source": [
    "# Create a and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[label_encoder, hasher, idf, vectorizer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "KONh1TWZFVrh",
    "outputId": "c4609dc3-374b-4357-afc6-f6c158c626f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "|             reviews|       rating|review_count|output_label|length|               token|      filtered_token|stopwords_count|  stopwords_percent|label|        hashed_token|           idf_token|            features|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "|Panda Express was...|5 star rating|          63|        good|   334|[panda, express, ...|[panda, express, ...|             37|0.11077844311377245|  1.0|(262144,[2711,610...|(262144,[2711,610...|(262146,[2711,610...|\n",
      "|The dude and I ca...|5 star rating|          63|        good|   770|[the, dude, and, ...|[dude, came, pand...|             80| 0.1038961038961039|  1.0|(262144,[9090,131...|(262144,[9090,131...|(262146,[9090,131...|\n",
      "|I ordered 5 total...|1 star rating|          63|         bad|   151|[i, ordered, 5, t...|[ordered, 5, tota...|             22| 0.1456953642384106|  0.0|(262144,[4402,978...|(262144,[4402,978...|(262146,[4402,978...|\n",
      "|I always order Pa...|3 star rating|          63|     descent|   628|[i, always, order...|[always, order, p...|             60|0.09554140127388536|  2.0|(262144,[329,2325...|(262144,[329,2325...|(262146,[329,2325...|\n",
      "|Decided to try Pa...|5 star rating|          63|        good|   261|[decided, to, try...|[decided, try, pa...|             32|0.12260536398467432|  1.0|(262144,[8086,335...|(262144,[8086,335...|(262146,[8086,335...|\n",
      "|I've never had a ...|4 star rating|          63|        good|   640|[i've, never, had...|[never, bad, expe...|             60|            0.09375|  1.0|(262144,[78,8287,...|(262144,[78,8287,...|(262146,[78,8287,...|\n",
      "|The family meal d...|1 star rating|          63|         bad|   129|[the, family, mea...|[family, meal, de...|             13|0.10077519379844961|  0.0|(262144,[19153,49...|(262144,[19153,49...|(262146,[19153,49...|\n",
      "|Quality has sever...|2 star rating|          63|     descent|   350|[quality, has, se...|[quality, severel...|             48|0.13714285714285715|  2.0|(262144,[16595,28...|(262144,[16595,28...|(262146,[16595,28...|\n",
      "|Paid for a bowl a...|1 star rating|          63|         bad|   158|[paid, for, a, bo...|[paid, bowl, entr...|             18|0.11392405063291139|  0.0|(262144,[15664,20...|(262144,[15664,20...|(262146,[15664,20...|\n",
      "|Order a bowl with...|1 star rating|          63|         bad|   151|[order, a, bowl, ...|[order, bowl, cho...|             19|0.12582781456953643|  0.0|(262144,[5381,172...|(262144,[5381,172...|(262146,[5381,172...|\n",
      "|Went through the ...|1 star rating|          63|         bad|   675|[went, through, t...|[went, drive-thro...|             62|0.09185185185185185|  0.0|(262144,[329,2325...|(262144,[329,2325...|(262146,[329,2325...|\n",
      "|When I think of p...|2 star rating|          63|     descent|   269|[when, i, think, ...|[think, panda, go...|             28|0.10408921933085502|  2.0|(262144,[78,2437,...|(262144,[78,2437,...|(262146,[78,2437,...|\n",
      "|Horrible is a und...|1 star rating|          63|         bad|   480|[horrible, is, a,...|[horrible, unders...|             45|            0.09375|  0.0|(262144,[4402,137...|(262144,[4402,137...|(262146,[4402,137...|\n",
      "|Yes the drive thr...|2 star rating|          63|     descent|   311|[yes, the, drive,...|[yes, drive, fast...|             32|0.10289389067524116|  2.0|(262144,[6796,172...|(262144,[6796,172...|(262146,[6796,172...|\n",
      "|Okay..so Panda is...|4 star rating|          63|        good|  1525|[okay..so, panda,...|[okay..so, panda,...|            149|0.09770491803278689|  1.0|(262144,[2437,755...|(262144,[2437,755...|(262146,[2437,755...|\n",
      "|Going through Dri...|2 star rating|          63|     descent|   653|[going, through, ...|[going, drive-thr...|             64|0.09800918836140889|  2.0|(262144,[2410,124...|(262144,[2410,124...|(262146,[2410,124...|\n",
      "|My entrees were a...|2 star rating|          63|     descent|   171|[my, entrees, wer...|[entrees, poor, s...|             21|0.12280701754385964|  2.0|(262144,[16091,31...|(262144,[16091,31...|(262146,[16091,31...|\n",
      "|I'm done being ri...|1 star rating|          63|         bad|  1065|[i'm, done, being...|[done, ripped, lo...|            106|0.09953051643192488|  0.0|(262144,[8985,134...|(262144,[8985,134...|(262146,[8985,134...|\n",
      "|Worst Panda in Fr...|1 star rating|          63|         bad|   417|[worst, panda, in...|[worst, panda, fr...|             47|0.11270983213429256|  0.0|(262144,[1536,232...|(262144,[1536,232...|(262146,[1536,232...|\n",
      "|I've been in here...|5 star rating|          63|        good|   410|[i've, been, in, ...|[many, times, say...|             37|0.09024390243902439|  1.0|(262144,[553,1489...|(262144,[553,1489...|(262146,[553,1489...|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit and transform data with pipeline\n",
    "pipeline_model = pipeline.fit(selected_df)\n",
    "cleaned_df = pipeline_model.transform(selected_df)\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72XEtR0OG0S4"
   },
   "source": [
    "### Create training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kYGmr5jgFV3q"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "# Break data down into a training set and a testing set\n",
    "training, testing = cleaned_df.randomSplit([0.7, 0.3], seed = 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "py6Vy9ymHL4x"
   },
   "source": [
    "### Fit and predict NaiveBaye model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vALxGjKCFVy5"
   },
   "outputs": [],
   "source": [
    "# Create a Naive Bayes model and fit training data\n",
    "model = NaiveBayes()\n",
    "predictor = model.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "cFzzWBfUFVuU",
    "outputId": "cf95eff5-6c21-4327-ea61-cbc3b1a0247f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|             reviews|       rating|review_count|output_label|length|               token|      filtered_token|stopwords_count|  stopwords_percent|label|        hashed_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|\"\"\"I never want t...|2 star rating|          29|     descent|  1410|[\"\"\"i, never, wan...|[\"\"\"i, never, wan...|            141|                0.1|  2.0|(262144,[14,4200,...|(262144,[14,4200,...|(262146,[14,4200,...|[-6054.9391900640...|[4.10747369219546...|       2.0|\n",
      "|\"\"\"No soup for yo...|1 star rating|         150|         bad|   272|[\"\"\"no, soup, for...|[\"\"\"no, soup, you...|             32|0.11764705882352941|  0.0|(262144,[1739,537...|(262144,[1739,537...|(262146,[1739,537...|[-2052.7273710531...|[5.66068646322026...|       2.0|\n",
      "|\"\"\"Panda\"\" says m...|4 star rating|          46|        good|   342|[\"\"\"panda\"\", says...|[\"\"\"panda\"\", says...|             36|0.10526315789473684|  1.0|(262144,[13781,21...|(262144,[13781,21...|(262146,[13781,21...|[-1480.2518794328...|[0.01504984992804...|       2.0|\n",
      "|\"\"\"There is much ...|1 star rating|          37|         bad|  1685|[\"\"\"there, is, mu...|[\"\"\"there, much, ...|            158|0.09376854599406528|  0.0|(262144,[512,929,...|(262144,[512,929,...|(262146,[512,929,...|[-7877.0789455567...|[1.0,5.1868540122...|       0.0|\n",
      "|\"(5/2/2018)  Stop...|3 star rating|          41|     descent|  1372|[\"(5/2/2018),  st...|[\"(5/2/2018),  st...|            140|0.10204081632653061|  2.0|(262144,[1854,232...|(262144,[1854,232...|(262146,[1854,232...|[-9527.8320339369...|[2.63553734785716...|       2.0|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tranform the model with the testing data\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ld09ZCgsHvqa",
    "outputId": "4483863f-4b34-451e-b7e0-4a6cf6d1fa30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting reviews was: 0.671084\n"
     ]
    }
   ],
   "source": [
    "# Use the Class Evaluator for a cleaner description\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPIi3htI1a2R"
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Create (prediction, label) pairs\n",
    "predictionAndLabel = test_results.select(\"prediction\", \"label\").rdd\n",
    "\n",
    "# Generate confusion matrix\n",
    "metrics = MulticlassMetrics(predictionAndLabel)\n",
    "print(metrics.confusionMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "xNYnmYCKdvwV",
    "outputId": "ba96fb39-6a70-4f62-ddfd-25b1f4a2c041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[2067.,   46.,  286.],\n",
      "             [ 219., 1115.,  259.],\n",
      "             [ 702.,  179.,  462.]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVc5IPj2-KnE"
   },
   "source": [
    "### Fit and predict with RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nP8jUE9n-Phh"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ng6PCJWNAVfa"
   },
   "outputs": [],
   "source": [
    "# create randomforest model and fit into training dataset\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_predictor = rf_model.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "1Fvl28ovA7sX",
    "outputId": "18923f83-893b-416c-f006-d32400e7b617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|             reviews|       rating|review_count|output_label|length|               token|      filtered_token|stopwords_count|  stopwords_percent|label|        hashed_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|\"\"\"I never want t...|2 star rating|          29|     descent|  1410|[\"\"\"i, never, wan...|[\"\"\"i, never, wan...|            141|                0.1|  2.0|(262144,[14,4200,...|(262144,[14,4200,...|(262146,[14,4200,...|[8.49940571908119...|[0.42497028595405...|       0.0|\n",
      "|\"\"\"No soup for yo...|1 star rating|         150|         bad|   272|[\"\"\"no, soup, for...|[\"\"\"no, soup, you...|             32|0.11764705882352941|  0.0|(262144,[1739,537...|(262144,[1739,537...|(262146,[1739,537...|[8.75398543440841...|[0.43769927172042...|       0.0|\n",
      "|\"\"\"Panda\"\" says m...|4 star rating|          46|        good|   342|[\"\"\"panda\"\", says...|[\"\"\"panda\"\", says...|             36|0.10526315789473684|  1.0|(262144,[13781,21...|(262144,[13781,21...|(262146,[13781,21...|[9.41388830781453...|[0.47069441539072...|       0.0|\n",
      "|\"\"\"There is much ...|1 star rating|          37|         bad|  1685|[\"\"\"there, is, mu...|[\"\"\"there, much, ...|            158|0.09376854599406528|  0.0|(262144,[512,929,...|(262144,[512,929,...|(262146,[512,929,...|[10.0224038751091...|[0.50112019375545...|       0.0|\n",
      "|\"(5/2/2018)  Stop...|3 star rating|          41|     descent|  1372|[\"(5/2/2018),  st...|[\"(5/2/2018),  st...|            140|0.10204081632653061|  2.0|(262144,[1854,232...|(262144,[1854,232...|(262146,[1854,232...|[9.04791287612951...|[0.45239564380647...|       0.0|\n",
      "+--------------------+-------------+------------+------------+------+--------------------+--------------------+---------------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform the model with testing data \n",
    "# Tranform the model with the testing data\n",
    "test_results = rf_predictor.transform(testing)\n",
    "test_results.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AlpxjpbRHUtJ",
    "outputId": "2721e285-1b6b-480c-bc93-386f3a15e010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting reviews was: 0.280607\n"
     ]
    }
   ],
   "source": [
    "# Use the Class Evaluator for a cleaner description\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "rf_acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting reviews was: %f\" % rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "id": "-RmBi8c2HgOa",
    "outputId": "c8059513-fc02-4e8c-fd69-1e4ba46c44a2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8662425919b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulticlassMetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Create (prediction, label) pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictionAndLabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Create (prediction, label) pairs\n",
    "predictionAndLabel = test_results.select(\"prediction\", \"label\").rdd\n",
    "\n",
    "# Generate confusion matrix\n",
    "metrics = MulticlassMetrics(predictionAndLabel)\n",
    "print(metrics.confusionMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CjrJ8COIK0S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdba3oPDixtv"
   },
   "source": [
    "### Sentimental Analysis with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kigSTDNBi2bJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "9XJqE8tGi73e",
    "outputId": "358f19c1-5b66-4bd4-ae58-77b8608ac890"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panda Express was on point tonight! I ordered ...</td>\n",
       "      <td>5 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dude and I came to this Panda Express arou...</td>\n",
       "      <td>5 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered 5 total plates  fried rice  chow mai...</td>\n",
       "      <td>1 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always order Panda Express from here and the...</td>\n",
       "      <td>3 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decided to try Panda Expess one more time.Corp...</td>\n",
       "      <td>5 star rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews         rating\n",
       "0  Panda Express was on point tonight! I ordered ...  5 star rating\n",
       "1  The dude and I came to this Panda Express arou...  5 star rating\n",
       "2  I ordered 5 total plates  fried rice  chow mai...  1 star rating\n",
       "3  I always order Panda Express from here and the...  3 star rating\n",
       "4  Decided to try Panda Expess one more time.Corp...  5 star rating"
      ]
     },
     "execution_count": 228,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(url)\n",
    "reviews = reviews.iloc[:,0:2]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0u-NysGTlwKi"
   },
   "source": [
    "### Clean up data, Changing rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "XPv4q_pujE_F",
    "outputId": "f2dd11a8-1318-495c-c430-b7f0d08f0bc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panda Express was on point tonight! I ordered ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dude and I came to this Panda Express arou...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered 5 total plates  fried rice  chow mai...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always order Panda Express from here and the...</td>\n",
       "      <td>descent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decided to try Panda Expess one more time.Corp...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews   rating\n",
       "0  Panda Express was on point tonight! I ordered ...     good\n",
       "1  The dude and I came to this Panda Express arou...     good\n",
       "2  I ordered 5 total plates  fried rice  chow mai...      bad\n",
       "3  I always order Panda Express from here and the...  descent\n",
       "4  Decided to try Panda Expess one more time.Corp...     good"
      ]
     },
     "execution_count": 229,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use defined function above to re-create rating column\n",
    "reviews[\"rating\"] = reviews[\"rating\"].apply(rating_category)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqiBaemMp3sd"
   },
   "source": [
    "### Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "BdhwGZf8r_Oy",
    "outputId": "0972ffed-a90d-4bbc-de9f-b4b1e6f657a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panda Express was on point tonight! I ordered ...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Panda, Express, was, on, point, tonight!, I, ...</td>\n",
       "      <td>63</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dude and I came to this Panda Express arou...</td>\n",
       "      <td>good</td>\n",
       "      <td>[The, dude, and, I, came, to, this, Panda, Exp...</td>\n",
       "      <td>149</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered 5 total plates  fried rice  chow mai...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[I, ordered, 5, total, plates, fried, rice, ch...</td>\n",
       "      <td>28</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always order Panda Express from here and the...</td>\n",
       "      <td>descent</td>\n",
       "      <td>[I, always, order, Panda, Express, from, here,...</td>\n",
       "      <td>122</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decided to try Panda Expess one more time.Corp...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Decided, to, try, Panda, Expess, one, more, t...</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ... char_count\n",
       "0  Panda Express was on point tonight! I ordered ...  ...        334\n",
       "1  The dude and I came to this Panda Express arou...  ...        770\n",
       "2  I ordered 5 total plates  fried rice  chow mai...  ...        151\n",
       "3  I always order Panda Express from here and the...  ...        628\n",
       "4  Decided to try Panda Expess one more time.Corp...  ...        261\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create word count, and character count\n",
    "reviews[\"word_list\"] = reviews[\"reviews\"].apply(lambda x: x.split())\n",
    "reviews[\"word_count\"] = reviews[\"word_list\"].apply(lambda x: len(x))\n",
    "reviews[\"char_count\"] = reviews[\"reviews\"].apply(lambda x: len(x))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7I-pX8ptBWx"
   },
   "outputs": [],
   "source": [
    "# look at average length of each word in each review\n",
    "def average_word_length(word_list)->int:\n",
    "    \"\"\"calculate the average word length in each review\n",
    "    \"\"\"\n",
    "    word_length = []\n",
    "    for word in word_list: \n",
    "        word_length.append(len(word))\n",
    "    return np.mean(word_length)\n",
    "\n",
    "assert average_word_length([\"test\", \"test12\"])==5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "c_NyvXHGxBDc",
    "outputId": "b99e4b43-cbb7-4596-b40a-2bb829ae6e88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panda Express was on point tonight! I ordered ...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Panda, Express, was, on, point, tonight!, I, ...</td>\n",
       "      <td>63</td>\n",
       "      <td>334</td>\n",
       "      <td>4.253968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dude and I came to this Panda Express arou...</td>\n",
       "      <td>good</td>\n",
       "      <td>[The, dude, and, I, came, to, this, Panda, Exp...</td>\n",
       "      <td>149</td>\n",
       "      <td>770</td>\n",
       "      <td>4.167785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered 5 total plates  fried rice  chow mai...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[I, ordered, 5, total, plates, fried, rice, ch...</td>\n",
       "      <td>28</td>\n",
       "      <td>151</td>\n",
       "      <td>4.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always order Panda Express from here and the...</td>\n",
       "      <td>descent</td>\n",
       "      <td>[I, always, order, Panda, Express, from, here,...</td>\n",
       "      <td>122</td>\n",
       "      <td>628</td>\n",
       "      <td>4.155738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decided to try Panda Expess one more time.Corp...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Decided, to, try, Panda, Expess, one, more, t...</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "      <td>5.390244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ... average_word_length\n",
       "0  Panda Express was on point tonight! I ordered ...  ...            4.253968\n",
       "1  The dude and I came to this Panda Express arou...  ...            4.167785\n",
       "2  I ordered 5 total plates  fried rice  chow mai...  ...            4.357143\n",
       "3  I always order Panda Express from here and the...  ...            4.155738\n",
       "4  Decided to try Panda Expess one more time.Corp...  ...            5.390244\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"average_word_length\"] = reviews[\"word_list\"].apply(average_word_length)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WGrTkGMDzwaj",
    "outputId": "c0159b62-8127-4ec5-d56d-51e9d9567770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 233,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fBqUZ3iKxxYv",
    "outputId": "20e67824-7612-4bc6-c38d-812dacc7d6eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stop_word_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panda Express was on point tonight! I ordered ...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Panda, Express, was, on, point, tonight!, I, ...</td>\n",
       "      <td>63</td>\n",
       "      <td>334</td>\n",
       "      <td>4.253968</td>\n",
       "      <td>28</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dude and I came to this Panda Express arou...</td>\n",
       "      <td>good</td>\n",
       "      <td>[The, dude, and, I, came, to, this, Panda, Exp...</td>\n",
       "      <td>149</td>\n",
       "      <td>770</td>\n",
       "      <td>4.167785</td>\n",
       "      <td>69</td>\n",
       "      <td>0.463087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered 5 total plates  fried rice  chow mai...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[I, ordered, 5, total, plates, fried, rice, ch...</td>\n",
       "      <td>28</td>\n",
       "      <td>151</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always order Panda Express from here and the...</td>\n",
       "      <td>descent</td>\n",
       "      <td>[I, always, order, Panda, Express, from, here,...</td>\n",
       "      <td>122</td>\n",
       "      <td>628</td>\n",
       "      <td>4.155738</td>\n",
       "      <td>59</td>\n",
       "      <td>0.483607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decided to try Panda Expess one more time.Corp...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Decided, to, try, Panda, Expess, one, more, t...</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "      <td>5.390244</td>\n",
       "      <td>8</td>\n",
       "      <td>0.195122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ... stop_word_percent\n",
       "0  Panda Express was on point tonight! I ordered ...  ...          0.444444\n",
       "1  The dude and I came to this Panda Express arou...  ...          0.463087\n",
       "2  I ordered 5 total plates  fried rice  chow mai...  ...          0.285714\n",
       "3  I always order Panda Express from here and the...  ...          0.483607\n",
       "4  Decided to try Panda Expess one more time.Corp...  ...          0.195122\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words, and get stopwords percentage\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "reviews[\"stop_word_count\"] = reviews[\"word_list\"].apply(lambda x: len([word for word in x if word.lower() in stop_words]))\n",
    "reviews[\"stop_word_percent\"] = reviews[\"stop_word_count\"]/reviews[\"word_count\"]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXniEdi-077A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XoOzFOn1jUu"
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZvjUjw2b08Ha",
    "outputId": "9352ade3-6d73-4b84-afd6-dd4065bc3acd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stop_word_percent</th>\n",
       "      <th>lowercase_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panda Express was on point tonight! I ordered ...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Panda, Express, was, on, point, tonight!, I, ...</td>\n",
       "      <td>63</td>\n",
       "      <td>334</td>\n",
       "      <td>4.253968</td>\n",
       "      <td>28</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>panda express was on point tonight i ordered t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dude and I came to this Panda Express arou...</td>\n",
       "      <td>good</td>\n",
       "      <td>[The, dude, and, I, came, to, this, Panda, Exp...</td>\n",
       "      <td>149</td>\n",
       "      <td>770</td>\n",
       "      <td>4.167785</td>\n",
       "      <td>69</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>the dude and i came to this panda express arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered 5 total plates  fried rice  chow mai...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[I, ordered, 5, total, plates, fried, rice, ch...</td>\n",
       "      <td>28</td>\n",
       "      <td>151</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>i ordered 5 total plates fried rice chow main ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always order Panda Express from here and the...</td>\n",
       "      <td>descent</td>\n",
       "      <td>[I, always, order, Panda, Express, from, here,...</td>\n",
       "      <td>122</td>\n",
       "      <td>628</td>\n",
       "      <td>4.155738</td>\n",
       "      <td>59</td>\n",
       "      <td>0.483607</td>\n",
       "      <td>i always order panda express from here and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decided to try Panda Expess one more time.Corp...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Decided, to, try, Panda, Expess, one, more, t...</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "      <td>5.390244</td>\n",
       "      <td>8</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>decided to try panda expess one more timecorpo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ...                                  lowercase_reviews\n",
       "0  Panda Express was on point tonight! I ordered ...  ...  panda express was on point tonight i ordered t...\n",
       "1  The dude and I came to this Panda Express arou...  ...  the dude and i came to this panda express arou...\n",
       "2  I ordered 5 total plates  fried rice  chow mai...  ...  i ordered 5 total plates fried rice chow main ...\n",
       "3  I always order Panda Express from here and the...  ...  i always order panda express from here and the...\n",
       "4  Decided to try Panda Expess one more time.Corp...  ...  decided to try panda expess one more timecorpo...\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower case all the reviews, and remove all the punctuations\n",
    "reviews[\"lowercase_reviews\"] = reviews[\"reviews\"].apply(lambda x: \" \".join(word.lower() for word in x.split()))\n",
    "reviews[\"lowercase_reviews\"] = reviews[\"lowercase_reviews\"].str.replace('[^\\w\\s]',\"\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "hRG0k48k3tBV",
    "outputId": "8cc1cad9-b0c9-4572-ad8d-7219402b0ab1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stop_word_percent</th>\n",
       "      <th>lowercase_reviews</th>\n",
       "      <th>clean_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panda Express was on point tonight! I ordered ...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Panda, Express, was, on, point, tonight!, I, ...</td>\n",
       "      <td>63</td>\n",
       "      <td>334</td>\n",
       "      <td>4.253968</td>\n",
       "      <td>28</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>panda express was on point tonight i ordered t...</td>\n",
       "      <td>panda express point tonight ordered mobile app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dude and I came to this Panda Express arou...</td>\n",
       "      <td>good</td>\n",
       "      <td>[The, dude, and, I, came, to, this, Panda, Exp...</td>\n",
       "      <td>149</td>\n",
       "      <td>770</td>\n",
       "      <td>4.167785</td>\n",
       "      <td>69</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>the dude and i came to this panda express arou...</td>\n",
       "      <td>dude came panda express around end july 2020 h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered 5 total plates  fried rice  chow mai...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[I, ordered, 5, total, plates, fried, rice, ch...</td>\n",
       "      <td>28</td>\n",
       "      <td>151</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>i ordered 5 total plates fried rice chow main ...</td>\n",
       "      <td>ordered 5 total plates fried rice chow main do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always order Panda Express from here and the...</td>\n",
       "      <td>descent</td>\n",
       "      <td>[I, always, order, Panda, Express, from, here,...</td>\n",
       "      <td>122</td>\n",
       "      <td>628</td>\n",
       "      <td>4.155738</td>\n",
       "      <td>59</td>\n",
       "      <td>0.483607</td>\n",
       "      <td>i always order panda express from here and the...</td>\n",
       "      <td>always order panda express problem ever place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decided to try Panda Expess one more time.Corp...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Decided, to, try, Panda, Expess, one, more, t...</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "      <td>5.390244</td>\n",
       "      <td>8</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>decided to try panda expess one more timecorpo...</td>\n",
       "      <td>decided try panda expess one timecorporations ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ...                                      clean_reviews\n",
       "0  Panda Express was on point tonight! I ordered ...  ...  panda express point tonight ordered mobile app...\n",
       "1  The dude and I came to this Panda Express arou...  ...  dude came panda express around end july 2020 h...\n",
       "2  I ordered 5 total plates  fried rice  chow mai...  ...  ordered 5 total plates fried rice chow main do...\n",
       "3  I always order Panda Express from here and the...  ...  always order panda express problem ever place ...\n",
       "4  Decided to try Panda Expess one more time.Corp...  ...  decided try panda expess one timecorporations ...\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words\n",
    "reviews[\"clean_reviews\"] = reviews[\"lowercase_reviews\"].apply(lambda x: \" \".join(word for word in x.split() if word not in stop_words))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p0Iy6Lg74MWE",
    "outputId": "fa555086-501d-4a11-8b5c-b68e7091f8d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food          18670\n",
       "panda         10282\n",
       "chicken        9602\n",
       "order          8020\n",
       "time           6692\n",
       "express        6561\n",
       "get            6174\n",
       "like           5817\n",
       "service        5807\n",
       "one            5682\n",
       "good           5472\n",
       "location       5390\n",
       "rice           4913\n",
       "go             4619\n",
       "place          4271\n",
       "got            4220\n",
       "back           4102\n",
       "always         4042\n",
       "dont           3947\n",
       "would          3922\n",
       "orange         3713\n",
       "ordered        3615\n",
       "even           3272\n",
       "minutes        3202\n",
       "wait           3097\n",
       "never          3039\n",
       "customer       3030\n",
       "didnt          2999\n",
       "im             2988\n",
       "drive          2867\n",
       "line           2754\n",
       "really         2722\n",
       "people         2719\n",
       "went           2719\n",
       "said           2699\n",
       "fresh          2668\n",
       "asked          2665\n",
       "great          2653\n",
       "beef           2649\n",
       "staff          2556\n",
       "chinese        2548\n",
       "give           2488\n",
       "fast           2478\n",
       "ive            2418\n",
       "chow           2246\n",
       "also           2226\n",
       "told           2181\n",
       "eat            2169\n",
       "come           2151\n",
       "mein           2124\n",
       "us             2108\n",
       "restaurant     2084\n",
       "going          2077\n",
       "make           2068\n",
       "sauce          2063\n",
       "shrimp         2053\n",
       "manager        2042\n",
       "know           2035\n",
       "fried          2030\n",
       "times          1937\n",
       "dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the frequency of words, and remove nonsense words\n",
    "pd.Series(\" \".join(reviews[\"clean_reviews\"]).split()).value_counts()[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "iCRR_oXy4iX_",
    "outputId": "9ec0b844-3da8-40ab-b556-986a34115787"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stop_word_percent</th>\n",
       "      <th>lowercase_reviews</th>\n",
       "      <th>clean_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panda Express was on point tonight! I ordered ...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Panda, Express, was, on, point, tonight!, I, ...</td>\n",
       "      <td>63</td>\n",
       "      <td>334</td>\n",
       "      <td>4.253968</td>\n",
       "      <td>28</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>panda express was on point tonight i ordered t...</td>\n",
       "      <td>point tonight ordered mobile app picked order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dude and I came to this Panda Express arou...</td>\n",
       "      <td>good</td>\n",
       "      <td>[The, dude, and, I, came, to, this, Panda, Exp...</td>\n",
       "      <td>149</td>\n",
       "      <td>770</td>\n",
       "      <td>4.167785</td>\n",
       "      <td>69</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>the dude and i came to this panda express arou...</td>\n",
       "      <td>dude came around end july 2020 havent use goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered 5 total plates  fried rice  chow mai...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[I, ordered, 5, total, plates, fried, rice, ch...</td>\n",
       "      <td>28</td>\n",
       "      <td>151</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>i ordered 5 total plates fried rice chow main ...</td>\n",
       "      <td>ordered 5 total plates fried rice chow main do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always order Panda Express from here and the...</td>\n",
       "      <td>descent</td>\n",
       "      <td>[I, always, order, Panda, Express, from, here,...</td>\n",
       "      <td>122</td>\n",
       "      <td>628</td>\n",
       "      <td>4.155738</td>\n",
       "      <td>59</td>\n",
       "      <td>0.483607</td>\n",
       "      <td>i always order panda express from here and the...</td>\n",
       "      <td>always order problem ever place order plate sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decided to try Panda Expess one more time.Corp...</td>\n",
       "      <td>good</td>\n",
       "      <td>[Decided, to, try, Panda, Expess, one, more, t...</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "      <td>5.390244</td>\n",
       "      <td>8</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>decided to try panda expess one more timecorpo...</td>\n",
       "      <td>decided try expess one timecorporations sent c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ...                                      clean_reviews\n",
       "0  Panda Express was on point tonight! I ordered ...  ...  point tonight ordered mobile app picked order ...\n",
       "1  The dude and I came to this Panda Express arou...  ...  dude came around end july 2020 havent use goin...\n",
       "2  I ordered 5 total plates  fried rice  chow mai...  ...  ordered 5 total plates fried rice chow main do...\n",
       "3  I always order Panda Express from here and the...  ...  always order problem ever place order plate sm...\n",
       "4  Decided to try Panda Expess one more time.Corp...  ...  decided try expess one timecorporations sent c...\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_stop_words = [\"food\", \"panda\", \"got\", \"im\",\"ive\",\"come\", \"restaurant\", \"express\"]\n",
    "reviews[\"clean_reviews\"] = reviews[\"clean_reviews\"].apply(lambda x: \" \".join(word for word in x.split() if word not in other_stop_words))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jMPtGITAIXNA",
    "outputId": "14a344b8-ba8d-452f-caa1-7942cd2f42c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29656"
      ]
     },
     "execution_count": 239,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = set()\n",
    "reviews[\"clean_reviews\"].str.split().apply(results.update)\n",
    "len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "HC7Pihf25PP5",
    "outputId": "95f01ae5-fe83-48e9-bb00-3901691b354d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stop_word_percent</th>\n",
       "      <th>clean_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>63</td>\n",
       "      <td>334</td>\n",
       "      <td>4.253968</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>point tonight ordered mobile app picked order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>149</td>\n",
       "      <td>770</td>\n",
       "      <td>4.167785</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>dude came around end july 2020 havent use goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>28</td>\n",
       "      <td>151</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>ordered 5 total plates fried rice chow main do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>descent</td>\n",
       "      <td>122</td>\n",
       "      <td>628</td>\n",
       "      <td>4.155738</td>\n",
       "      <td>0.483607</td>\n",
       "      <td>always order problem ever place order plate sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "      <td>5.390244</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>decided try expess one timecorporations sent c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating  ...                                      clean_reviews\n",
       "0     good  ...  point tonight ordered mobile app picked order ...\n",
       "1     good  ...  dude came around end july 2020 havent use goin...\n",
       "2      bad  ...  ordered 5 total plates fried rice chow main do...\n",
       "3  descent  ...  always order problem ever place order plate sm...\n",
       "4     good  ...  decided try expess one timecorporations sent c...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get final dataset\n",
    "final_dataset = reviews.iloc[:,[1,3,4,5,7,9]]\n",
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "AH_GvHKHQ_ln",
    "outputId": "6a2162a8-23a6-4209-cac7-8a39726db65e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>point tonight ordered mobile app picked order ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dude came around end july 2020 havent use goin...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered 5 total plates fried rice chow main do...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>always order problem ever place order plate sm...</td>\n",
       "      <td>descent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decided try expess one timecorporations sent c...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_reviews   rating\n",
       "0  point tonight ordered mobile app picked order ...     good\n",
       "1  dude came around end july 2020 havent use goin...     good\n",
       "2  ordered 5 total plates fried rice chow main do...      bad\n",
       "3  always order problem ever place order plate sm...  descent\n",
       "4  decided try expess one timecorporations sent c...     good"
      ]
     },
     "execution_count": 263,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dataset = final_dataset[[\"clean_reviews\",\"rating\"]]\n",
    "temp_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M-j8AQFaY2oi",
    "outputId": "0d41f5f8-f60a-41f1-b114-b06a0506c893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17620"
      ]
     },
     "execution_count": 300,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size = len(temp_dataset[\"clean_reviews\"])\n",
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "311XFmC7X9ba"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(temp_dataset[\"rating\"])\n",
    "encoded_y = label_encoder.transform(temp_dataset[\"rating\"])\n",
    "y_categorical = to_categorical(encoded_y)\n",
    "\n",
    "y_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FF6bP8aXLpV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        tf.cast(temp_dataset[\"clean_reviews\"].values,tf.string), \n",
    "        tf.cast(y_categorical, tf.float64), \n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "ZI1gB1cNSUUQ",
    "outputId": "9e600726-678f-40a6-a4d9-e9e89174512b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: point tonight ordered mobile app picked order pick time ready time double checked order correct gave us extra utensils sauce hot fresh superb customer service well best experience ...\n",
      "Label: [0. 0. 1.]\n",
      "\n",
      "Review: dude came around end july 2020 havent use going inside lot drive thrus surprised stumbled upon one one usually go closed nightwe went drive thru quick process plate super greens along honey walnut shr ...\n",
      "Label: [0. 0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in tf_dataset.batch(2).take(1):\n",
    "    for review, label in zip(X_batch.numpy(), y_batch.numpy()):\n",
    "        print(\"Review:\", review.decode(\"utf-8\")[:200], \"...\")\n",
    "        print(\"Label:\", label)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoN2In7dSUPe"
   },
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 1000)\n",
    "    X_batch = tf.strings.regex_replace(X_batch, rb\"<br\\s*/?>\", b\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "2l3fVxRhS5xq",
    "outputId": "3610d5a7-fff4-4e74-ff7c-479f6e3b56e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 72), dtype=string, numpy=\n",
       " array([[b'point', b'tonight', b'ordered', b'mobile', b'app', b'picked',\n",
       "         b'order', b'pick', b'time', b'ready', b'time', b'double',\n",
       "         b'checked', b'order', b'correct', b'gave', b'us', b'extra',\n",
       "         b'utensils', b'sauce', b'hot', b'fresh', b'superb', b'customer',\n",
       "         b'service', b'well', b'best', b'experience', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "        [b'dude', b'came', b'around', b'end', b'july', b'havent', b'use',\n",
       "         b'going', b'inside', b'lot', b'drive', b'thrus', b'surprised',\n",
       "         b'stumbled', b'upon', b'one', b'one', b'usually', b'go',\n",
       "         b'closed', b'nightwe', b'went', b'drive', b'thru', b'quick',\n",
       "         b'process', b'plate', b'super', b'greens', b'along', b'honey',\n",
       "         b'walnut', b'shrimp', b'kung', b'pao', b'chicken', b'everything',\n",
       "         b'delicious', b'dude', b'half', b'fried', b'rice', b'half',\n",
       "         b'chow', b'mein', b'orange', b'chicken', b'fire', b'steak',\n",
       "         b'new', b'said', b'steak', b'dish', b'deliciouswe', b'wait',\n",
       "         b'minutes', b'super', b'greens', b'wasnt', b'long', b'wait',\n",
       "         b'staff', b'friendly', b'remembered', b'car', b'staff',\n",
       "         b'wearing', b'face', b'masks', b'overall', b'nice', b'location']],\n",
       "       dtype=object)>, <tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
       " array([[0., 0., 1.],\n",
       "        [0., 0., 1.]])>)"
      ]
     },
     "execution_count": 321,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hp0X6xJsS5vp"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in tf_dataset.batch(32).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6TBzroFxS5sE",
    "outputId": "476cf841-a19a-4307-e12b-04f8264e2541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23083"
      ]
     },
     "execution_count": 292,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HqpRnAGsS5qC"
   },
   "outputs": [],
   "source": [
    "# vocab_size can be a parameter to be tunned\n",
    "vocab_size = 10000\n",
    "truncated_vocabulary = [\n",
    "    word for word, count in vocabulary.most_common()[:vocab_size]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "fdf_U90FS5md",
    "outputId": "92db8285-891f-4214-b7db-34cf55369e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "9\n",
      "15\n",
      "1\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {word: index for index, word in enumerate(truncated_vocabulary)}\n",
    "for word in b\"I like orange chicken patchouli\".split():\n",
    "    print(word_to_id.get(word) or vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pH-x05CaS5ka"
   },
   "outputs": [],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkB9tcLjbDw6"
   },
   "outputs": [],
   "source": [
    "train_size = int(.7*data_size)\n",
    "test_size = int(.3*data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1mJzhu1VeYg"
   },
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch\n",
    "\n",
    "train_set = tf_dataset.take(train_size).repeat().batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFS7Ga0Eay2q"
   },
   "outputs": [],
   "source": [
    "test_set = tf_dataset.skip(train_size).repeat().batch(32).map(preprocess)\n",
    "test_set = test_set.map(encode_words).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "Odl5sd-UVeUk",
    "outputId": "679219ff-a046-495c-b00e-89f2535ca986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 382  261   14 ...    0    0    0]\n",
      " [1920   58   91 ...    1  456  783]\n",
      " [  14  565  290 ...    0    0    0]\n",
      " ...\n",
      " [  24  990  353 ...    0    0    0]\n",
      " [  17  193  931 ...    0    0    0]\n",
      " [ 129   32   13 ...    0    0    0]], shape=(32, 49), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]], shape=(32, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_set.take(1):\n",
    "    print(X_batch)\n",
    "    print(y_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4e8EGvtWkaf"
   },
   "outputs": [],
   "source": [
    "train_size = int(.7*data_size)\n",
    "test_size = int(.3*data_size)\n",
    "\n",
    "train_dataset = tf_dataset.take(train_size)\n",
    "test_dataset = tf_dataset.skip(train_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l8sh8CfEZ0tc",
    "outputId": "21a06f84-aa57-484b-f92c-aee9d5e77750"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12334"
      ]
     },
     "execution_count": 305,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q27U3WvyZm8B",
    "outputId": "aa024647-acec-4b60-fb0e-b9fbd9918a62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((), (3,)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 304,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzExMeVqZIGo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tggpTgd9Vnb7"
   },
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
    "                           mask_zero=True, # not shown in the book\n",
    "                           input_shape=[None]),\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(256),\n",
    "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLN_fsDQeEvC"
   },
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "587jwAGfd-6k"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FNgvIO2Hb1MV",
    "outputId": "4fa3adc8-996e-4803-a90f-3f8c24ad9342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "385/385 [==============================] - 202s 525ms/step - loss: 0.7434 - accuracy: 0.6643 - val_loss: 0.6676 - val_accuracy: 0.7072\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 201s 523ms/step - loss: 0.5421 - accuracy: 0.7686 - val_loss: 0.7248 - val_accuracy: 0.6722\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 203s 527ms/step - loss: 0.3964 - accuracy: 0.8445 - val_loss: 0.9480 - val_accuracy: 0.6384\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 198s 515ms/step - loss: 0.3073 - accuracy: 0.8851 - val_loss: 0.9930 - val_accuracy: 0.6617\n",
      "Epoch 5/5\n",
      "385/385 [==============================] - 198s 515ms/step - loss: 0.2242 - accuracy: 0.9198 - val_loss: 1.1122 - val_accuracy: 0.6559\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, steps_per_epoch=train_size // 32, epochs=5, validation_data= test_set, validation_steps=test_size//32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmW8q7NvVnP6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLgBswRCXMTC"
   },
   "source": [
    "### Tokenize clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "TSyNS8eDXQ4Q",
    "outputId": "4e512b3f-a1f9-44e7-96bd-c5e120da3797"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>stop_word_percent</th>\n",
       "      <th>clean_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>63</td>\n",
       "      <td>334</td>\n",
       "      <td>4.253968</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>[315, 330, 18, 1219, 468, 570, 2, 133, 3, 90, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>149</td>\n",
       "      <td>770</td>\n",
       "      <td>4.167785</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>[1731, 64, 97, 430, 2079, 2284, 510, 290, 45, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>28</td>\n",
       "      <td>151</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>[18, 116, 555, 314, 51, 10, 39, 427, 629, 17, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>descent</td>\n",
       "      <td>122</td>\n",
       "      <td>628</td>\n",
       "      <td>4.155738</td>\n",
       "      <td>0.483607</td>\n",
       "      <td>[14, 2, 284, 72, 12, 2, 58, 127, 91, 101, 121,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "      <td>5.390244</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>[219, 122, 6374, 7, 12393, 992, 2805, 94, 212,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating  ...                                      clean_reviews\n",
       "0     good  ...  [315, 330, 18, 1219, 468, 570, 2, 133, 3, 90, ...\n",
       "1     good  ...  [1731, 64, 97, 430, 2079, 2284, 510, 290, 45, ...\n",
       "2      bad  ...  [18, 116, 555, 314, 51, 10, 39, 427, 629, 17, ...\n",
       "3  descent  ...  [14, 2, 284, 72, 12, 2, 58, 127, 91, 101, 121,...\n",
       "4     good  ...  [219, 122, 6374, 7, 12393, 992, 2805, 94, 212,...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
    "\n",
    "# tokenize\n",
    "tokenizer = Tokenizer(num_words = 29656, lower= True)\n",
    "tokenizer.fit_on_texts(final_dataset[\"clean_reviews\"])\n",
    "final_dataset[\"clean_reviews\"] = tokenizer.texts_to_sequences(final_dataset[\"clean_reviews\"])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obDB1dsOIPWz"
   },
   "outputs": [],
   "source": [
    "final_dataset[\"clean_reviews\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIodh5Hi6arT"
   },
   "source": [
    "### Creating Training and Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "s3_aZuEKl-Jt",
    "outputId": "ce205b4d-af7f-4a4c-dc58-50f442b24003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (12334,)\n",
      "Shape of X_test: (5286,)\n",
      "Shape of y_train: (12334,)\n",
      "Shape of y_test: (5286,)\n"
     ]
    }
   ],
   "source": [
    "# separate train, test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, X_aux_train, X_aux_test, y_train, y_test = train_test_split(final_dataset[\"clean_reviews\"], final_dataset[\"stop_word_percent\"], final_dataset[\"rating\"], test_size = 0.3, random_state = 42)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2LpTS8pEhM5G",
    "outputId": "e1b8452b-ff06-481e-b566-8fbbba53332e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5286,)"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aux_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTO9w5nEYQQc"
   },
   "source": [
    "### Scale the data and create one-hot-encoding for rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eilB0YSRYPe3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2feDyvSYPid"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpbeu2YH7Y1s"
   },
   "outputs": [],
   "source": [
    "# create padding\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "maxlen = max(final_dataset[\"clean_reviews\"].apply(lambda x: len(x)))\n",
    "\n",
    "X_train = pad_sequences(X_train, padding=\"post\", maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding=\"post\", maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCI0_F9piDjv"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, SimpleRNN, LSTM, Embedding, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lxOHdRFvKSub",
    "outputId": "a51805d7-5d5d-4375-c2e8-a535b67d806f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 248,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "P4Whyouv9R3c",
    "outputId": "28118b99-4239-467b-957f-898ebac6aba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12334, 303, 1)\n",
      "(5286, 303, 1)\n",
      "(12334, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape the data\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Activation, SimpleRNN, LSTM\n",
    "# from keras import optimizers\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1],1))\n",
    "# X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1],1))\n",
    "# X_aux_train = np.array(X_aux_train).reshape((X_aux_train.shape[0],1))\n",
    "# X_aux_test = np.array(X_aux_test).reshape((X_aux_test.shape[0],1))\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(X_aux_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "rTNmQCqUC0Ya",
    "outputId": "e76417fe-94a6-47e0-aac2-855bd5a01160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12334, 423)\n",
      "(5286, 423)\n",
      "(12334,)\n"
     ]
    }
   ],
   "source": [
    "# reshape the data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, SimpleRNN, LSTM\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1]))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1]))\n",
    "X_aux_train = np.array(X_aux_train).reshape((X_aux_train.shape[0]))\n",
    "X_aux_test = np.array(X_aux_test).reshape((X_aux_test.shape[0]))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_aux_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FYPZ3qrG-aIS"
   },
   "source": [
    "### Fit the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uH4LY6vi-biC"
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "def rnn_model():\n",
    "  model = Sequential(name = \"RNN_Model\")\n",
    "  model.add(Embedding(tokenizer.num_words, 128, input_shape = [None]))\n",
    "  model.add(LSTM(128, return_sequences=True))\n",
    "  model.add(LSTM(128, return_sequences=False))\n",
    "  model.add(Dense(num_classes, activation='softmax', name = \"output\"))\n",
    "  model.summary()\n",
    "\n",
    "  adam = optimizers.Adam(lr = 0.001)\n",
    "  model.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph91mERKi6ba"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn = rnn_model, epochs = 20, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "colab_type": "code",
    "id": "M1LV_d3t_M7m",
    "outputId": "fc431743-67a9-4a58-ef00-ed81b3241467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 128)         3795968   \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 4,059,523\n",
      "Trainable params: 4,059,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "275/771 [=========>....................] - ETA: 7:13 - loss: 1.0725 - accuracy: 0.4489"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-2335a970b5b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_categorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train_categorical, validation_data = (X_test, y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLfzRrfe_mBi"
   },
   "outputs": [],
   "source": [
    "def read_data(url):\n",
    "    \"\"\"read in data from a url\n",
    "    \"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "create_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
