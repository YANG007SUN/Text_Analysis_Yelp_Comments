{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "create_model.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY9TOKfodvwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "884a173c-95cf-4f66-da67-8116e0a15d2b"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 2.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-2.4.7'\n",
        "# spark_version = 'spark-2.<enter version>'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,094 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [903 kB]\n",
            "Get:16 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,876 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,430 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,385 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [906 kB]\n",
            "Fetched 7,866 kB in 4s (1,945 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5PNfsCGdvwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"YelpReview\").getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRXeIzKxAbNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import col, udf,length\n",
        "from pyspark.sql.types import StringType"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Eo6aW_mIU7v",
        "colab_type": "text"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaEsSu5HdvwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "50e81522-f389-46a2-d919-63740a9dcd46"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://usc-bootcamp-yelpreview-text-analysis.s3.us-east-2.amazonaws.com/reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "raw_df = spark.read.csv(SparkFiles.get(\"reviews.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "raw_df.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+------------+\n",
            "|             reviews|       rating|review_count|\n",
            "+--------------------+-------------+------------+\n",
            "|Panda Express was...|5 star rating|          63|\n",
            "|The dude and I ca...|5 star rating|          63|\n",
            "|I ordered 5 total...|1 star rating|          63|\n",
            "|I always order Pa...|3 star rating|          63|\n",
            "|Decided to try Pa...|5 star rating|          63|\n",
            "|I've never had a ...|4 star rating|          63|\n",
            "|The family meal d...|1 star rating|          63|\n",
            "|Quality has sever...|2 star rating|          63|\n",
            "|Paid for a bowl a...|1 star rating|          63|\n",
            "|Order a bowl with...|1 star rating|          63|\n",
            "|Went through the ...|1 star rating|          63|\n",
            "|When I think of p...|2 star rating|          63|\n",
            "|Horrible is a und...|1 star rating|          63|\n",
            "|Yes the drive thr...|2 star rating|          63|\n",
            "|Okay..so Panda is...|4 star rating|          63|\n",
            "|Going through Dri...|2 star rating|          63|\n",
            "|My entrees were a...|2 star rating|          63|\n",
            "|I'm done being ri...|1 star rating|          63|\n",
            "|Worst Panda in Fr...|1 star rating|          63|\n",
            "|I've been in here...|5 star rating|          63|\n",
            "+--------------------+-------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9XxqONt3584",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "835ab974-bcca-4496-a043-0847a0a8d076"
      },
      "source": [
        "\n",
        "raw_df.groupBy(\"rating\").count().show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+-----+\n",
            "|       rating|count|\n",
            "+-------------+-----+\n",
            "|3 star rating| 1967|\n",
            "|4 star rating| 2222|\n",
            "|1 star rating| 7959|\n",
            "|2 star rating| 2566|\n",
            "|5 star rating| 2906|\n",
            "+-------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BZ0W3-m8moG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new column function - reduce dimension of rating column into 3 categories\n",
        "def rating_category(rating:str)->str:\n",
        "  \"\"\"create new column \n",
        "  \"\"\"\n",
        "  if rating in [\"1 star rating\"]:\n",
        "      return \"bad\"\n",
        "  elif rating in [\"2 star rating\", \"3 star rating\"]:\n",
        "      return \"descent\"\n",
        "  else: \n",
        "      return \"good\"\n",
        "\n",
        "assert rating_category(\"1 star rating\")==\"bad\"\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXkOnFY-BPTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "109a4c4e-ce9f-40fc-9cab-2052c1d61642"
      },
      "source": [
        "# Store a user defined function\n",
        "convert_rating = udf(rating_category, StringType())\n",
        "convert_rating"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.rating_category>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-u1o_de3y1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "8abb6074-e7cb-4dcd-f949-13551490f2ea"
      },
      "source": [
        "# add new column\n",
        "selected_df = raw_df.withColumn(\"output_label\", convert_rating(col(\"rating\")))\n",
        "selected_df = selected_df.withColumn(\"length\", length(selected_df[\"reviews\"]))\n",
        "selected_df.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+------------+------------+------+\n",
            "|             reviews|       rating|review_count|output_label|length|\n",
            "+--------------------+-------------+------------+------------+------+\n",
            "|Panda Express was...|5 star rating|          63|        good|   334|\n",
            "|The dude and I ca...|5 star rating|          63|        good|   770|\n",
            "|I ordered 5 total...|1 star rating|          63|         bad|   151|\n",
            "|I always order Pa...|3 star rating|          63|     descent|   628|\n",
            "|Decided to try Pa...|5 star rating|          63|        good|   261|\n",
            "|I've never had a ...|4 star rating|          63|        good|   640|\n",
            "|The family meal d...|1 star rating|          63|         bad|   129|\n",
            "|Quality has sever...|2 star rating|          63|     descent|   350|\n",
            "|Paid for a bowl a...|1 star rating|          63|         bad|   158|\n",
            "|Order a bowl with...|1 star rating|          63|         bad|   151|\n",
            "|Went through the ...|1 star rating|          63|         bad|   675|\n",
            "|When I think of p...|2 star rating|          63|     descent|   269|\n",
            "|Horrible is a und...|1 star rating|          63|         bad|   480|\n",
            "|Yes the drive thr...|2 star rating|          63|     descent|   311|\n",
            "|Okay..so Panda is...|4 star rating|          63|        good|  1525|\n",
            "|Going through Dri...|2 star rating|          63|     descent|   653|\n",
            "|My entrees were a...|2 star rating|          63|     descent|   171|\n",
            "|I'm done being ri...|1 star rating|          63|         bad|  1065|\n",
            "|Worst Panda in Fr...|1 star rating|          63|         bad|   417|\n",
            "|I've been in here...|5 star rating|          63|        good|   410|\n",
            "+--------------------+-------------+------------+------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gw825XQD9ZR",
        "colab_type": "text"
      },
      "source": [
        "### Feature Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-YLw4x6D3Xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz57Y3xxEHRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create all features to the dataset\n",
        "label_encoder = StringIndexer(inputCol=\"output_label\", outputCol=\"label\")\n",
        "tokenizer = Tokenizer(inputCol=\"reviews\", outputCol=\"token\")\n",
        "stop_word_remover = StopWordsRemover(inputCol=\"token\", outputCol=\"filtered_token\")\n",
        "hasher = HashingTF(inputCol=\"filtered_token\", outputCol=\"hashed_token\")\n",
        "idf = IDF(inputCol=\"hashed_token\", outputCol=\"idf_token\")\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmeYECzrEHTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "vectorizer = VectorAssembler(inputCols = [\"idf_token\", \"length\"], outputCol = \"features\")\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4U-I2I6FTV9",
        "colab_type": "text"
      },
      "source": [
        "### Create a Pipeline to Automate The Data Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6EGuPcMFVop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[label_encoder, tokenizer, stop_word_remover, hasher, idf, vectorizer])\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KONh1TWZFVrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "02b64260-4cae-4078-e368-a16a02447f58"
      },
      "source": [
        "# fit and transform data with pipeline\n",
        "pipeline_model = pipeline.fit(selected_df)\n",
        "cleaned_df = pipeline_model.transform(selected_df)\n",
        "cleaned_df.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+------------+------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|             reviews|       rating|review_count|output_label|length|label|               token|      filtered_token|        hashed_token|           idf_token|            features|\n",
            "+--------------------+-------------+------------+------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Panda Express was...|5 star rating|          63|        good|   334|  1.0|[panda, express, ...|[panda, express, ...|(262144,[2711,610...|(262144,[2711,610...|(262145,[2711,610...|\n",
            "|The dude and I ca...|5 star rating|          63|        good|   770|  1.0|[the, dude, and, ...|[dude, came, pand...|(262144,[9090,131...|(262144,[9090,131...|(262145,[9090,131...|\n",
            "|I ordered 5 total...|1 star rating|          63|         bad|   151|  0.0|[i, ordered, 5, t...|[ordered, 5, tota...|(262144,[4402,978...|(262144,[4402,978...|(262145,[4402,978...|\n",
            "|I always order Pa...|3 star rating|          63|     descent|   628|  2.0|[i, always, order...|[always, order, p...|(262144,[329,2325...|(262144,[329,2325...|(262145,[329,2325...|\n",
            "|Decided to try Pa...|5 star rating|          63|        good|   261|  1.0|[decided, to, try...|[decided, try, pa...|(262144,[8086,335...|(262144,[8086,335...|(262145,[8086,335...|\n",
            "|I've never had a ...|4 star rating|          63|        good|   640|  1.0|[i've, never, had...|[never, bad, expe...|(262144,[78,8287,...|(262144,[78,8287,...|(262145,[78,8287,...|\n",
            "|The family meal d...|1 star rating|          63|         bad|   129|  0.0|[the, family, mea...|[family, meal, de...|(262144,[19153,49...|(262144,[19153,49...|(262145,[19153,49...|\n",
            "|Quality has sever...|2 star rating|          63|     descent|   350|  2.0|[quality, has, se...|[quality, severel...|(262144,[16595,28...|(262144,[16595,28...|(262145,[16595,28...|\n",
            "|Paid for a bowl a...|1 star rating|          63|         bad|   158|  0.0|[paid, for, a, bo...|[paid, bowl, entr...|(262144,[15664,20...|(262144,[15664,20...|(262145,[15664,20...|\n",
            "|Order a bowl with...|1 star rating|          63|         bad|   151|  0.0|[order, a, bowl, ...|[order, bowl, cho...|(262144,[5381,172...|(262144,[5381,172...|(262145,[5381,172...|\n",
            "|Went through the ...|1 star rating|          63|         bad|   675|  0.0|[went, through, t...|[went, drive-thro...|(262144,[329,2325...|(262144,[329,2325...|(262145,[329,2325...|\n",
            "|When I think of p...|2 star rating|          63|     descent|   269|  2.0|[when, i, think, ...|[think, panda, go...|(262144,[78,2437,...|(262144,[78,2437,...|(262145,[78,2437,...|\n",
            "|Horrible is a und...|1 star rating|          63|         bad|   480|  0.0|[horrible, is, a,...|[horrible, unders...|(262144,[4402,137...|(262144,[4402,137...|(262145,[4402,137...|\n",
            "|Yes the drive thr...|2 star rating|          63|     descent|   311|  2.0|[yes, the, drive,...|[yes, drive, fast...|(262144,[6796,172...|(262144,[6796,172...|(262145,[6796,172...|\n",
            "|Okay..so Panda is...|4 star rating|          63|        good|  1525|  1.0|[okay..so, panda,...|[okay..so, panda,...|(262144,[2437,755...|(262144,[2437,755...|(262145,[2437,755...|\n",
            "|Going through Dri...|2 star rating|          63|     descent|   653|  2.0|[going, through, ...|[going, drive-thr...|(262144,[2410,124...|(262144,[2410,124...|(262145,[2410,124...|\n",
            "|My entrees were a...|2 star rating|          63|     descent|   171|  2.0|[my, entrees, wer...|[entrees, poor, s...|(262144,[16091,31...|(262144,[16091,31...|(262145,[16091,31...|\n",
            "|I'm done being ri...|1 star rating|          63|         bad|  1065|  0.0|[i'm, done, being...|[done, ripped, lo...|(262144,[8985,134...|(262144,[8985,134...|(262145,[8985,134...|\n",
            "|Worst Panda in Fr...|1 star rating|          63|         bad|   417|  0.0|[worst, panda, in...|[worst, panda, fr...|(262144,[1536,232...|(262144,[1536,232...|(262145,[1536,232...|\n",
            "|I've been in here...|5 star rating|          63|        good|   410|  1.0|[i've, been, in, ...|[many, times, say...|(262144,[553,1489...|(262144,[553,1489...|(262145,[553,1489...|\n",
            "+--------------------+-------------+------------+------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72XEtR0OG0S4",
        "colab_type": "text"
      },
      "source": [
        "### Create training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYGmr5jgFV3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned_df.randomSplit([0.7, 0.3], seed = 43)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py6Vy9ymHL4x",
        "colab_type": "text"
      },
      "source": [
        "### Fit and predict NaiveBaye model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vALxGjKCFVy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Naive Bayes model and fit training data\n",
        "model = NaiveBayes()\n",
        "predictor = model.fit(training)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFzzWBfUFVuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "be6393ae-47ca-4116-aabc-f005a920d1f2"
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+------------+------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|             reviews|       rating|review_count|output_label|length|label|               token|      filtered_token|        hashed_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-------------+------------+------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|\"\"\"I never want t...|2 star rating|          29|     descent|  1410|  2.0|[\"\"\"i, never, wan...|[\"\"\"i, never, wan...|(262144,[14,4200,...|(262144,[14,4200,...|(262145,[14,4200,...|[-6053.7857632465...|[4.13879883391400...|       2.0|\n",
            "|\"\"\"No soup for yo...|1 star rating|         150|         bad|   272|  0.0|[\"\"\"no, soup, for...|[\"\"\"no, soup, you...|(262144,[1739,537...|(262144,[1739,537...|(262145,[1739,537...|[-2051.6199122621...|[5.64402636245754...|       2.0|\n",
            "|\"\"\"Panda\"\" says m...|4 star rating|          46|        good|   342|  1.0|[\"\"\"panda\"\", says...|[\"\"\"panda\"\", says...|(262144,[13781,21...|(262144,[13781,21...|(262145,[13781,21...|[-1479.2494390256...|[0.01501897282376...|       2.0|\n",
            "|\"\"\"There is much ...|1 star rating|          37|         bad|  1685|  0.0|[\"\"\"there, is, mu...|[\"\"\"there, much, ...|(262144,[512,929,...|(262144,[512,929,...|(262145,[512,929,...|[-7875.9243210429...|[1.0,5.4133228629...|       0.0|\n",
            "|\"(5/2/2018)  Stop...|3 star rating|          41|     descent|  1372|  2.0|[\"(5/2/2018),  st...|[\"(5/2/2018),  st...|(262144,[1854,232...|(262144,[1854,232...|(262145,[1854,232...|[-9526.6360893246...|[2.65845100269346...|       2.0|\n",
            "+--------------------+-------------+------------+------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld09ZCgsHvqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f552e72c-147a-4846-abb0-c6006716ec16"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.671084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNYnmYCKdvwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}